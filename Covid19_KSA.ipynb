{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from github import Github\n",
    "import pandas as pd\n",
    "import io\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_csv_file_on_github(access_token,repo_name,file_name):\n",
    "    # using an access token\n",
    "    g = Github(access_token)\n",
    "    # Find your repository and path of README.md\n",
    "    repo=g.get_user().get_repo(repo_name)\n",
    "    file = repo.get_contents(file_name)\n",
    "    s=str(file.decoded_content,'utf-8')\n",
    "    data = io.StringIO(s) \n",
    "    return pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_dataframe_to_csv_file_on_github(access_token,repo_name,file_name,dataframe,commit_message):\n",
    "    # using an access token\n",
    "    g = Github(access_token)\n",
    "    # Find your repository and path of README.md\n",
    "    repo=g.get_user().get_repo(repo_name)\n",
    "    file = repo.get_contents(file_name)\n",
    "    temp_file =io.StringIO()\n",
    "    dataframe.to_csv(temp_file,index=False)\n",
    "    repo.update_file(file_name,commit_message,temp_file.getvalue() , file.sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access_token=\"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\"\n",
    "#repo_name=\"Covid-19-KSA-Data\"\n",
    "\n",
    "access_token=\"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\"\n",
    "repo_name=\"KSA_COVID19\"\n",
    "\n",
    "new_confirmed_cases={}\n",
    "new_recovered_cases={}\n",
    "new_deaths={}\n",
    "\n",
    "\n",
    "#headers_name=[]\n",
    "update_date=\"\"\n",
    "commit_message=\"\"\n",
    "\n",
    "\n",
    "#create data frame form github file \n",
    "\n",
    "Confirmed_df = get_dataframe_from_csv_file_on_github(access_token,repo_name,file_name=\"Daily_Confirmed_By_City.csv\")\n",
    "Recovered_df = get_dataframe_from_csv_file_on_github(access_token,repo_name,file_name=\"Daily_Recovered_By_City.csv\")\n",
    "Deaths_df = get_dataframe_from_csv_file_on_github(access_token,repo_name,file_name=\"Daily_Deaths_By_City.csv\")\n",
    "\n",
    "#KSA_Cities_xlsx_url=\"https://raw.githubusercontent.com/EslamAlaaZaki/Covid-19-KSA-Data/main/KSA_Cities.xlsx\"\n",
    "KSA_Cities_xlsx_url=\"https://raw.githubusercontent.com/abubakrsaad/KSA_COVID19/master/KSA_Cities.xlsx\"\n",
    "KSA_Cities_df = pd.read_excel(KSA_Cities_xlsx_url)\n",
    "\n",
    "#filters colums in KSA_Cities_df to keep only (City ,City Arabic  Name)\n",
    "KSA_Cities_df=KSA_Cities_df.drop([KSA_Cities_df.columns[1]], axis = 1)\n",
    "KSA_Cities_df=KSA_Cities_df.drop(KSA_Cities_df.columns[2:6], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get('https://sehhty.com/sa-covid-cities')\n",
    "if request.status_code==200:\n",
    "    html_text=request.text\n",
    "    soup=BeautifulSoup(html_text,'lxml')\n",
    "    \n",
    "    #get update date\n",
    "    div_tags=soup.find_all('div')\n",
    "    for div in div_tags:\n",
    "        if div.text.find(\"آخر تحديث\") !=-1 and len(div.text)<50:\n",
    "            update_date=div.text.split()[1].split(':')[1]\n",
    "            update_date=update_date.split(\"-\")[1]+\"/\"+update_date.split(\"-\")[2]+\"/\"+update_date.split(\"-\")[0]\n",
    "            \n",
    "            #descripe commit message for github push\n",
    "            commit_message=\"last update date: \"+update_date\n",
    "            \n",
    "            #sub one day\n",
    "            format = '%m/%d/%Y' # The format\n",
    "            update_date = (datetime.datetime.strptime(update_date, format)-datetime.timedelta(days=1)).strftime(format)\n",
    "            break\n",
    "    \n",
    "    #create data structures\n",
    "    new_confirmed_cases['City Arabic  Name']=[]\n",
    "    new_confirmed_cases[update_date]=[]\n",
    "    \n",
    "    new_recovered_cases['City Arabic  Name']=[]\n",
    "    new_recovered_cases[update_date]=[]\n",
    "    \n",
    "    new_deaths['City Arabic  Name']=[]\n",
    "    new_deaths[update_date]=[]\n",
    "    \n",
    "            \n",
    "    #get header names\n",
    "    #headers=soup.find('thead').find_all('th')\n",
    "   \n",
    "    #for header in headers:\n",
    "        #headers_name.append(header.text)\n",
    "    \n",
    "    #get rows\n",
    "    rows=soup.find('tbody').find_all('tr')\n",
    "    for row in rows:\n",
    "        columns=row.find_all('td')\n",
    "        i=0\n",
    "        for column in columns:\n",
    "            #filter total row\n",
    "            if column.text=='':\n",
    "                break\n",
    "            #write city name\n",
    "            if i==1: \n",
    "                new_confirmed_cases['City Arabic  Name'].append(column.text)\n",
    "                new_recovered_cases['City Arabic  Name'].append(column.text)\n",
    "                new_deaths['City Arabic  Name'].append(column.text)\n",
    "            #write confirmed_case\n",
    "            if i==3:\n",
    "                new_confirmed_cases[update_date].append(int(column.text.replace('+','')))\n",
    "            #write recovered_case\n",
    "            if i==5:\n",
    "                new_recovered_cases[update_date].append(int(column.text.replace('+','')))\n",
    "            #wirte deaths\n",
    "            if i==7:\n",
    "                new_deaths[update_date].append(int(column.text.replace('+','')))\n",
    "            i=i+1\n",
    "            \n",
    "            \n",
    "    #convert data dic to dataframes\n",
    "    new_confirmed_cases_df=pd.DataFrame(new_confirmed_cases,columns=['City Arabic  Name',update_date])\n",
    "    new_recovered_cases_df=pd.DataFrame(new_recovered_cases,columns=['City Arabic  Name',update_date])\n",
    "    new_deaths_df=pd.DataFrame(new_deaths,columns=['City Arabic  Name',update_date])\n",
    "    \n",
    "    \n",
    "    # join with KSA_Cities_df to get city english name\n",
    "    new_confirmed_cases_df=pd.merge(new_confirmed_cases_df, KSA_Cities_df, on='City Arabic  Name', how='left')\n",
    "    new_recovered_cases_df=pd.merge(new_recovered_cases_df, KSA_Cities_df, on='City Arabic  Name', how='left')\n",
    "    new_deaths_df=pd.merge(new_deaths_df, KSA_Cities_df, on='City Arabic  Name', how='left')\n",
    "     \n",
    "    \n",
    "    #remove arabic name column\n",
    "    new_confirmed_cases_df=new_confirmed_cases_df.drop(['City Arabic  Name'], axis = 1)\n",
    "    new_recovered_cases_df=new_recovered_cases_df.drop(['City Arabic  Name'], axis = 1)\n",
    "    new_deaths_df=new_deaths_df.drop(['City Arabic  Name'], axis = 1)\n",
    "    \n",
    "    #group by \n",
    "    \n",
    "    new_confirmed_cases_df=new_confirmed_cases_df.groupby(['City ']).sum()\n",
    "    new_recovered_cases_df=new_recovered_cases_df.groupby(['City ']).sum()\n",
    "    new_deaths_df=new_deaths_df.groupby(['City ']).sum()\n",
    "\n",
    "    \n",
    "    \n",
    "    # join with old data to insert new data and push it into github\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    ##########################################################################\n",
    "    if Confirmed_df.columns[-1] != new_confirmed_cases_df.columns[0]:\n",
    "        Confirmed_df=pd.merge(Confirmed_df,new_confirmed_cases_df, on='City ', how='left')\n",
    "        Confirmed_df[update_date]=Confirmed_df[update_date].fillna(0)\n",
    "        Confirmed_df[update_date]=Confirmed_df[update_date].astype('int64')\n",
    "        #push new data\n",
    "        push_dataframe_to_csv_file_on_github(access_token,repo_name,\"Daily_Confirmed_By_City.csv\",Confirmed_df,commit_message)\n",
    "        \n",
    "    #############################################################################\n",
    "    if Recovered_df.columns[-1] != new_recovered_cases_df.columns[0]:\n",
    "        Recovered_df=pd.merge(Recovered_df,new_recovered_cases_df, on='City ', how='left')\n",
    "        Recovered_df[update_date]=Recovered_df[update_date].fillna(0)\n",
    "        Recovered_df[update_date]=Recovered_df[update_date].astype('int64')\n",
    "        #push new data\n",
    "        push_dataframe_to_csv_file_on_github(access_token,repo_name,\"Daily_Recovered_By_City.csv\",Recovered_df,commit_message)\n",
    "    #########################################################################\n",
    "    if Deaths_df.columns[-1] != new_deaths_df.columns[0]:\n",
    "        Deaths_df=pd.merge(Deaths_df,new_deaths_df, on='City ', how='left')\n",
    "        Deaths_df[update_date]=Deaths_df[update_date].fillna(0)\n",
    "        Deaths_df[update_date]=Deaths_df[update_date].astype('int64')\n",
    "        #push new data\n",
    "        push_dataframe_to_csv_file_on_github(access_token,repo_name,\"Daily_Deaths_By_City.csv\",Deaths_df,commit_message)\n",
    "    Confirmed_df.to_excel(\"Confirmed_df.xlsx\")\n",
    "    Recovered_df.to_excel(\"Recovered_df.xlsx\")\n",
    "    Deaths_df.to_excel(\"Deaths_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
